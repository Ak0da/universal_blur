#version 330
/**
  \file data-files/shader/MotionBlur/MotionBlur_gather.pix

  This is designed to read from a G3D-style velocity (optical flow) buffer.
  For performance, you could just write out velocity in the desired 
  format rather than adjusting it per texture fetch.

  G3D Innovation Engine http://casual-effects.com/g3d
  Copyright 2000-2019, Morgan McGuire
  All rights reserved
  Available under the BSD License
*/
// Included by all of the blur shaders
#include <compatibility.glsl>

#expect maxBlurRadius "int > 0"
#expect MODEL "PHYSICAL, ARTIST, or NONE"
#expect numSamplesOdd
#expect SPEED_DIRECTION "1 if sampling in speed direction, 0 if sampling perpendicularly to speed direction"

// Set to 0 to make very thin objects appear correct, set to 1 to reduce noise but
// undersample single-pixel thick moving objects
#define SMOOTHER 1

/** Unprocessed differences between previous and current frame in screen space. Guard band. */
uniform sampler2D   SS_POSITION_CHANGE_buffer;
uniform vec4        SS_POSITION_CHANGE_readMultiplyFirst;
uniform vec4        SS_POSITION_CHANGE_readAddSecond;

/** Uses the same encoding as SS_POSITION_CHANGE but has three channels.  No guard band. */
uniform sampler2D   neighborMinMax_buffer;

/** Source image in RGB, normalized CoC in A. Used for DoF. */
uniform sampler2D	blurSourceBuffer;
uniform float       lowResolutionFactor;
uniform int         maxCoCRadiusPixels;
uniform float       invNearBlurRadiusPixels;

#if SPEED_DIRECTION
    const bool isSpeedDirection = true;
#else
    const bool isSpeedDirection = false;
#endif

/** No guard band. */
uniform sampler2D   colorBuffer;
#if !SPEED_DIRECTION
uniform sampler2D   nearColorBuffer;
#endif

/** Typical hyperbolic depth buffer: close values are greater than distant values. Guard band. */
uniform sampler2D   depthBuffer;

/** 32x32 tiled random numbers */
uniform sampler2D   randomBuffer;

/** In fraction of frame duration */
uniform float       exposureTime;

uniform ivec2       trimBandThickness;

/** Amount on [-0.5, 0.5] to randomly perturb samples by at each pixel */
float2              jitter;

/* Measured in pixels
   Make this smaller to better hide tile boundaries
   Make this bigger to get smoother blur (less noise) */
#define varianceThreshold 1.5

out float3 resultColor;

/*
#if SPEED_DIRECTION // HUGO ---------------------------------------
#if __VERSION__ < 130   // HUGO ---------------------------------------
#	define nearResult gl_FragData[0]
#	define blurResult gl_FragData[1]
#else
layout(location = 0) out float4 nearResult;
layout(location = 1) out float4 blurResult;
#endif
#else
out float3 blurResult;
#endif // SPEED_DIRECTION
*/

// Constant indicating locations wme we clamp against the minimum PSF, 1/2 pixel
const float HALF_PIX = 0.5;

/** Computes a pseudo-random number on [0, 1] from pixel position c. */
float hash(int2 c) {
#   if numSamplesOdd <= 5
	    // Use a simple checkerboard if you have very few samples; this gives too much ghosting 
        // for many scenes, however
        return float(int(c.x + c.y) & 1) * 0.5 + 0.25;
#   else
        return texelFetch(randomBuffer, int2(c.x & 31, c.y & 31), 0).r;
#   endif
}

float square(float x) { return x * x; }


/** Called from readAdjustedVelocity() and readAdjustedNeighborhoodVelocity() 

    (xy) is the velocity, z is the minimum blur radius in the tile for neighbor velocity
    and zero for expressive motion.
*/
//float3 readAdjustedVelocity(int2 C, sampler2D sampler, out float r) {
float3 readAdjustedVelocity(int2 C, int2 A, sampler2D sampler, out float r, out float CoC_ratio) { // HUGO ---------------------------------

	// Raw screen-space movement
    float3 q = texelFetch(sampler, C, 0).xyz * SS_POSITION_CHANGE_readMultiplyFirst.xyz + SS_POSITION_CHANGE_readAddSecond.xyz;
    float lenq = length(q.xy);

    // Convert the velocity to be a radius instead of a diameter, and scale it by
	// the exposure time
    r = lenq * 0.5 * exposureTime;
    q.z *= 0.5 * exposureTime;
    //bool rMuchLargerThanZero = (r >= 0.01);
    bool rMuchLargerThanZero = (r >= 0.1);  // HUGO -------------------------

    // Clamp to the usable distance
    r = clamp(r, HALF_PIX, float(maxBlurRadius));
	
    // If r is nearly zero, then we risk having a negligible value in lenq, so just return the original
    // vector, which can't be that long anyway if we entered this case
    if (rMuchLargerThanZero) {
        // Adjust q's length based on the newly clamped radius
        q.xy *= (r / lenq);
    }
//#if MODEL != NONE  // HUGO ---------------------------------------------
    else
    {
        q.xy = float2(1.0, 0.0);
    }

#if !SPEED_DIRECTION
    //if (!speedDirection){
        q.xy = float2(-q.y, q.x);
        //r=HALF_PIX;
        r=0.01;
    //}
#endif

    //float DoF_r = abs( (texelFetch(blurSourceBuffer, A, 0).a * 2.0) - 1.0 );
    //r += float(maxCoCRadiusPixels) * DoF_r;
    //r += lerp(0.0,float(maxCoCRadiusPixels), DoF_r);

    float DoF_r = (texelFetch(blurSourceBuffer, A, 0).a * 2.0) - 1.0;
    //float near = square(saturate(DoF_r * invNearBlurRadiusPixels));
    r += float(maxCoCRadiusPixels) * abs(DoF_r);
    CoC_ratio = DoF_r/r;
    //r *= sign(DoF_r);
//#endif
    return q;
}

/** 
  V[C] in the paper.

  v = half-velocity vector 
  r = magnitude of v
*/
/*
float3 readAdjustedVelocity(int2 C, out float r) {
    return readAdjustedVelocity(C, SS_POSITION_CHANGE_buffer, r);
}
*/
float3 readAdjustedVelocity(int2 C, int2 A, out float r, out float CoC_ratio) {  // HUGO ---------------------------------
    return readAdjustedVelocity(C, A, SS_POSITION_CHANGE_buffer, r, CoC_ratio);
}



/** NeighborMax[C] from the paper */
/*
float3 readAdjustedNeighborhoodVelocity(int2 C, out float r) {
    return readAdjustedVelocity(int2(C / float(maxBlurRadius)), neighborMinMax_buffer, r);
}
*/
float3 readAdjustedNeighborhoodVelocity(int2 C, int2 A, out float r, out float CoC_ratio) {  // HUGO ---------------------------------
    return readAdjustedVelocity(int2(C / float(maxBlurRadius)), A, neighborMinMax_buffer, r, CoC_ratio);
}

float cone(float dist, float r) {
    return saturate(1.0 - abs(dist) / r);
}


float fastCone(float dist, float invR) {
    return saturate(1.0 - abs(dist) * invR);
}

// A cone filter with maximum weight 1 at dist = 0 and min weight 0 at |v|=dist.
float cylinder(float dist, float r) {
    //return 1.0 - smoothstep(r * 0.95, r * 1.05, abs(dist));

    // Alternative: (marginally faster on GeForce, comparable quality)
    return sign(r - abs(dist)) * 0.5 + 0.5;

    // The following gives nearly identical results and may be faster on some hardware,
    // but is slower on GeForce
    //    return (abs(dist) <= r) ? 1.0 : 0.0;
}


/** 0 if depth_A << depth_B, 1 if depth_A >> z_depth, fades between when they are close */
float softDepthCompare(float depth_A, float depth_B) {
    // World space distance over which we are conservative about the classification
    // of "foreground" vs. "background".  Must be > 0.  
    // Increase if slanted surfaces aren't blurring enough.
    // Decrease if the background is bleeding into the foreground.
    // Fairly insensitive
    const float SOFT_DEPTH_EXTENT = 0.01;

    return saturate(1.0 - (depth_B - depth_A) / SOFT_DEPTH_EXTENT);
}


// For linear Z values where more negative = farther away from camera
float softZCompare(float z_A, float z_B) {
    // World space distance over which we are conservative about the classification
    // of "foreground" vs. "background".  Must be > 0.  
    // Increase if slanted surfaces aren't blurring enough.
    // Decrease if the background is bleeding into the foreground.
    // Fairly insensitive
    const float SOFT_Z_EXTENT = 0.1;

    return saturate(1.0 - (z_A - z_B) / SOFT_Z_EXTENT);
}

bool inNearField(float radiusPixels) {
    return radiusPixels > 0.25;
}


void main() {
    // Size of the screen
    int2 SCREEN_MAX = textureSize(colorBuffer, 0).xy + trimBandThickness * 2 - int2(1);
    int2 NO_TRIM_BAND_SCREEN_MAX = textureSize(colorBuffer, 0).xy - int2(1);

    // Center pixel
    int2 me       = int2(gl_FragCoord.xy);
    //bool isSpeedDirection = true; //true;

    // Location of center pixel in the downsized 
    // Account for the scaling down to 50% of original dimensions during blur
	//int2 A = int2(gl_FragCoord.xy * (direction * lowResolutionFactor + (ivec2(1) - direction)));
    int2 A = int2(gl_FragCoord.xy * lowResolutionFactor);
    float CoC_center = (texelFetch(blurSourceBuffer, A, 0).a * 2.0) - 1.0;
    float DoF_r = abs(CoC_center);
    DoF_r = float(maxCoCRadiusPixels) * DoF_r;

    
    
    

    float3 centerColor = texelFetch(colorBuffer, me - trimBandThickness, 0).rgb;
    resultColor = vec3(0);
    float totalCoverage = 0;
    float totalCoverageNear = 0;
    float4 resultColorNear;

    float depth_center = texelFetch(depthBuffer, me, 0).x;
    
    // Compute the maximum PSF in the neighborhood
    float r_neighborhood;
    float r_neighborhood_CoC_ratio;
    float2 v_neighborhood;
    float rmin_neighborhood;
    { 
       //float3 temp = readAdjustedNeighborhoodVelocity(me - trimBandThickness, r_neighborhood);
       float3 temp = readAdjustedNeighborhoodVelocity(me - trimBandThickness, A, r_neighborhood, r_neighborhood_CoC_ratio);   // HUGO ----------------------
       v_neighborhood    = temp.xy;
       rmin_neighborhood = temp.z;
    }
    
    // A pseudo-random number on [-0.5, 0.5]
    float jitter = hash(me) - 0.5;
    //jitter *= saturate( (1.0-abs(r_neighborhood_CoC_ratio)) * (r_neighborhood)*0.01); // HUGO ----------------------------
    jitter = 0.0; // HUGO ----------------------------

    // Compute PSF at me (this pixel)
    float  radius_center;
    float CoC_ratio_center;
    //float2 velocity_center = readAdjustedVelocity(me, radius_center).xy;
    float2 velocity_center = readAdjustedVelocity(me, A, radius_center, CoC_ratio_center).xy; // HUGO ---------------------------------
    

    // Above this pixel displacement, the center velocity overrides the neighborhood.
    // This ensures the overblurring occurs only on the interior of fast-moving objects
    // instead of in tiles outside of moving objects.
    const float centerOverrideThresholdPixels = 5;

    // Let w be a velocity direction (i.e., w is "omega", a unit vector in screen-space)
    // Let r be a half-velocity magnitude (i.e., a point-spread function radius)
    // If the center is moving very fast, sample along the center direction to avoid tile polution
    //float2 w_neighborhood = normalize((radius_center >= centerOverrideThresholdPixels) ? velocity_center : v_neighborhood);
    float2 w_neighborhood = normalize((radius_center >= centerOverrideThresholdPixels + DoF_r) ? velocity_center : v_neighborhood); // HUGO ----------------------

    // Choose the direction at this pixel to be the same as w_neighborhood if this pixel is not itself moving.
    // Don't adjust the radious--doing so causes the background to blur out when it is static.
    //float2 w_center = (radius_center < varianceThreshold) ? w_neighborhood : normalize(velocity_center);
    float2 w_center = (radius_center < varianceThreshold + DoF_r) ? w_neighborhood : normalize(velocity_center); // HUGO ----------------------

    
    

    // Accumulated color; start with the center sample
    // Higher initial weight increases the ability of the background
    // to overcome the out-blurred part of moving objects
    float invRadius_center = 1.0 / radius_center; 
    // float totalCoverage = (float(numSamplesOdd) / 40.0) * invRadius_center;
    // resultColor *= totalCoverage;
    float initialCoverage = (float(numSamplesOdd) / 40.0) * invRadius_center; // HUGO -------------------------------
    //float initialCoverage = 0.001;
    totalCoverage += initialCoverage;  // HUGO --------------------
    resultColor.rgb += centerColor*initialCoverage;

    float radius_sample = r_neighborhood;
    float radius_CoC_ratio = r_neighborhood_CoC_ratio;

    // HUGO (DEBUG ONLY) -------------------------------------------------------------------------------------------------
    //resultColor.xy = abs(v_neighborhood);
    //resultColor.z = 0.0;
    //resultColor = vec3(radius_center/maxCoCRadiusPixels);
    //vec3(texelFetch(blurSourceBuffer, A, 0).a);
    

    // The following branch is coherent on tile boundaries. It gives about a 12% speedup
    // to motion blur due to camera motion. Ideally, the tile boundaries are also warp (8 pixel) boundaries
    // to avoid divergence.
    //if ((rmin_neighborhood >= r_neighborhood) || 
    //    ((rmin_neighborhood >= r_neighborhood * 0.65) && (rmin_neighborhood >= 4))) {
    if (false) { // HUGO -----------------------------------------------------------------------------------------

        // Everything in this neighborhood is moving pretty fast; assume that
        // radius_sample == r_neighborhood and don't bother spending
        // bandwidth to actually read it per pixel
#       define COMPUTE_RADIUS_SAMPLE() 
// The inner loop of MotionBlur_gather.pix
// Sample along the largest PSF vector in the neighborhood
for (int i = 0; i < numSamplesOdd; ++i) {

    // The original algorithm ignores the center sample, but we include it because doing so
    // produces better results for thin objects at the expense of adding a slight amount of grain.
    // That is because the jitter will bounce this slightly off the actual center
#   if SMOOTHER
        if (i == numSamplesOdd / 2) { continue; }
#   endif
        
    // Signed step distance from X to Y.
    // Because cone(r_Y) = 0, we need this to never reach +/- r_neighborhood, even with jitter.
    // If this value is even slightly off then gaps and bands will appear in the blur.
    // This pattern is slightly different than the original paper.
    float t = clamp(2.4 * (float(i) + 1.0 + jitter) / (numSamplesOdd + 1.0) - 1.2, -1, 1);
    float dist = t * r_neighborhood;

    float2 sampling_direction = (((i & 1) == 1) ? w_center : w_neighborhood);

    float2 offset =
        // Alternate between the neighborhood direction and this pixel's direction.
        // This significantly helps avoid tile boundary problems when other are
        // two large velocities in a tile. Favor the neighborhood velocity on the farthest 
        // out taps (which also means that we get slightly more neighborhood taps, as we'd like)
        dist * sampling_direction;
        
    // Point being considered; offset and round to the nearest pixel center.
    // Then, clamp to the screen bounds
    int2 other = clamp(int2(offset + gl_FragCoord.xy), trimBandThickness, SCREEN_MAX);

    float depth_sample = texelFetch(depthBuffer, other, 0).x;

    // is other in the foreground or background of me?
    float inFront = softDepthCompare(depth_center, depth_sample);
    float inBack  = softDepthCompare(depth_sample, depth_center);
    

    // HUGO -------------------------------------------
    //inFront = 0.0;
    //inBack = 0.0;
    //float tempFront = inFront;
    //inFront = saturate(CoC_ratio_center) * inFront + (1-saturate(CoC_ratio_center)) * inBack;
    //inBack = saturate(CoC_ratio_center) * inBack + (1-saturate(CoC_ratio_center)) * tempFront;

    // Relative contribution of sample to the center
    float coverage_sample = 0.0;

    // Blurry me, estimate background
    coverage_sample += inBack * fastCone(dist, invRadius_center);
    //coverage_sample += inBack * 0.0; // HUGO --------------------------;
    //coverage_sample += max(inBack, radius_CoC_ratio) * 10.0; // HUGO --------------------------
    //coverage_sample += inBack * fastCone(dist, invRadius_center)  * (1+20*saturate(CoC_ratio_center)); // HUGO --------------------------;

    COMPUTE_RADIUS_SAMPLE();

    float3 color_sample    = texelFetch(colorBuffer, clamp(other - trimBandThickness, ivec2(0), NO_TRIM_BAND_SCREEN_MAX), 0).rgb;

    // Blurry other over any me
    coverage_sample += inFront * cone(dist, radius_sample);
    //coverage_sample += inFront * 0.0; // HUGO --------------------------
    //coverage_sample += max(inFront, radius_CoC_ratio) * 10.0; // HUGO --------------------------
    //coverage_sample += inFront * cone(dist, radius_sample) * (1+20*saturate(CoC_ratio_center)); // HUGO --------------------------

    // Mutually blurry me and other
    coverage_sample += 
    //0; // HUGO --------------------------------------------------------------------------------------------
		// Optimized implementation
		cylinder(dist, min(radius_center, radius_sample)) * 2.0;
		

//        coverage_sample = saturate(coverage_sample * abs(dot(normalize(velocity_sample), sampling_direction)));
//       coverage_sample = saturate(dot(normalize(velocity_sample), sampling_direction));
		// Code from paper:
		// cylinder(dist, radius_center) * cylinder(dist, radius_sample) * 2.0;


    //coverage_sample = 0.0; // HUGO -------------------------------------------------------------------

    // Accumulate (with premultiplied coverage)
    //resultColor   += color_sample * coverage_sample;
    // MUST UNCOMMENT TO WORK !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

    totalCoverage += coverage_sample;
}
    } else {
        // Read true velocity at each pixel
#       undef COMPUTE_RADIUS_SAMPLE

        // The actual velocity_sample vector will be ignored by the code below,
        // but the magnitude (radius_sample) of the blur is used.
//#       define COMPUTE_RADIUS_SAMPLE() { float2 velocity_sample = readAdjustedVelocity(other, radius_sample).xy; }
#       define COMPUTE_RADIUS_SAMPLE() { float2 velocity_sample = readAdjustedVelocity(other, A, radius_sample, radius_CoC_ratio).xy; }  // HUGO -----------
// The inner loop of MotionBlur_gather.pix
// Sample along the largest PSF vector in the neighborhood
for (int i = 0; i < numSamplesOdd; ++i) {

    // The original algorithm ignores the center sample, but we include it because doing so
    // produces better results for thin objects at the expense of adding a slight amount of grain.
    // That is because the jitter will bounce this slightly off the actual center
#   if SMOOTHER
        if (i == numSamplesOdd / 2) { continue; }
#   endif
        
    // Signed step distance from X to Y.
    // Because cone(r_Y) = 0, we need this to never reach +/- r_neighborhood, even with jitter.
    // If this value is even slightly off then gaps and bands will appear in the blur.
    // This pattern is slightly different than the original paper.
    float t = clamp(2.4 * (float(i) + 1.0 + jitter) / (numSamplesOdd + 1.0) - 1.2, -1, 1);
    //float t = clamp(2.4 * (float(i) + 1.0) / (numSamplesOdd + 1.0) - 1.2, -1, 1); // HUGO -------------------------------------
    // float dist = t * r_neighborhood;
    float dist = t * (maxCoCRadiusPixels);//28; ///20; // HUGO ----------------------------------------------------------------------------

    float2 sampling_direction = (((i & 1) == 1) ? w_center : w_neighborhood);

    float2 offset =
        // Alternate between the neighborhood direction and this pixel's direction.
        // This significantly helps avoid tile boundary problems when other are
        // two large velocities in a tile. Favor the neighborhood velocity on the farthest 
        // out taps (which also means that we get slightly more neighborhood taps, as we'd like)
        dist * sampling_direction;
        
    // Point being considered; offset and round to the nearest pixel center.
    // Then, clamp to the screen bounds
    int2 other = clamp(int2(offset + gl_FragCoord.xy), trimBandThickness, SCREEN_MAX);

    float depth_sample = texelFetch(depthBuffer, other, 0).x;

    // is other in the foreground or background of me?
    float inFront = softDepthCompare(depth_center, depth_sample);
    float inBack  = softDepthCompare(depth_sample, depth_center);

    // Relative contribution of sample to the center
    float coverage_sample = 0.0;

    float ratioDoF = abs(radius_CoC_ratio);
    float ratioMB = 1.0-ratioDoF;
    float CoC_sample = texelFetch(blurSourceBuffer, other, 0).a * 2.0 - 1.0;

    // Blurry me, estimate background
    //coverage_sample += inBack * fastCone(dist, invRadius_center);
    //coverage_sample += inBack * cone(dist, max(radius_sample,radius_center)); // HUGO ---------------------------------------------------------
    //coverage_sample += inBack * cone(dist, max(radius_sample,radius_center)); // HUGO ---------------------------------------------------------
    //coverage_sample += float(depth_sample<depth_center); // Works to color background // HUGO ---------------------------------------------------------
    //coverage_sample += inFront; // Works to color background // HUGO ---------------------------------------------------------
    //coverage_sample += float(depth_center > depth_sample); // Works to color background // HUGO ---------------------------------------------------------
    
    //coverage_sample += float(CoC_sample <= 0.25 && CoC_center <= 0.25); // Works to color background // HUGO ---------------------------------------------------------
    //coverage_sample += 10.0*float(CoC_sample >  0.25 && CoC_center <= 0.25); // Works to color background // HUGO ---------------------------------------------------------
    coverage_sample += float(CoC_sample >  0.25 && CoC_center <= 0.25); // Works to color background // HUGO ---------------------------------------------------------
    //coverage_sample += float(CoC_sample >  0.25 && CoC_center >  0.25); // Works to color background // HUGO ---------------------------------------------------------

    coverage_sample *= float(abs(dist) < radius_sample); // HUGO --------------------------------------

    //coverage_sample += inFront * square(saturate(radius_sample*sign(radius_CoC_ratio)/maxCoCRadiusPixels)) + inBack * square(saturate(-radius_sample*sign(radius_CoC_ratio)/maxCoCRadiusPixels)) ; // Works to color background // HUGO ---------------------------------------------------------
    //coverage_sample += inFront * square(saturate(ratioDoF*radius_sample*sign(radius_CoC_ratio)/maxCoCRadiusPixels)) + inBack * square(saturate(-ratioDoF*radius_sample*sign(radius_CoC_ratio)/maxCoCRadiusPixels)) ; // Works to color background // HUGO ---------------------------------------------------------
    //coverage_sample += inFront * cone(dist, ratioMB*radius_sample);//float(ratioMB*radius_sample > abs(dist)); FOR MB
    
    coverage_sample += 0.0; // HUGO --------------------------------------------------------------------------------------

    COMPUTE_RADIUS_SAMPLE();

    float3 color_sample    = texelFetch(colorBuffer, clamp(other - trimBandThickness, ivec2(0), NO_TRIM_BAND_SCREEN_MAX), 0).rgb;

    // Blurry other over any me
    //coverage_sample += inFront * cone(dist, radius_sample);
    coverage_sample += 0.0; // HUGO --------------------------------------------------------------------------------------
    //coverage_sample += max(inFront, radius_CoC_ratio) *  cone(dist, radius_sample); // HUGO ----------------------------------------------
    //coverage_sample += cone(dist, radius_sample); // HUGO ----------------------------------------------
    //coverage_sample += radius_CoC_ratio; //max(inFront, radius_CoC_ratio);


    // Mutually blurry me and other
    coverage_sample += 
        0.0; // HUGO -------------------------------------------------------------------------------------- 
		// Optimized implementation
		//cylinder(dist, min(radius_center, radius_sample)) * 2.0;
		
        // UNUSED BY DEFAULT
//        coverage_sample = saturate(coverage_sample * abs(dot(normalize(velocity_sample), sampling_direction)));
//       coverage_sample = saturate(dot(normalize(velocity_sample), sampling_direction));
		// Code from paper:
		// cylinder(dist, radius_center) * cylinder(dist, radius_sample) * 2.0;
    
    //coverage_sample = float(max(radius_sample, radius_center) > abs(dist)); // HUGO ---------------------------------------------------------------------------------------
    //coverage_sample = cylinder(dist, max(radius_center, radius_sample))/(abs(dist)+0.01); // HUGO ---------------------------------------------------------------------------------------

    /*
    {// HUGO EXPERIMENT ---------------------------------------------------------------------------------- 
        
        
        //float r_A = radius_center*CoC_ratio_center;
        //float r_B = radius_sample*radius_CoC_ratio;
        float packedA = texelFetch(blurSourceBuffer, A, 0).a;
        float r_A = (packedA * 2.0 - 1.0) * float(maxCoCRadiusPixels);
        float packedB = texelFetch(blurSourceBuffer, other, 0).a;
        float r_B = (packedB * 2.0 - 1.0) * float(maxCoCRadiusPixels);
        float nearFieldness_A = saturate(r_A * 4.0);
        float invB = 1.0 / (0.01 + abs(r_B));
        float wNormal  =
            // Only consider mid- or background pixels (allows inpainting of the near-field)
            float(! inNearField(r_B)) *
            
            // Only blur B over A if B is closer to the viewer (allow a few pixels of slop, and smooth the transition)
			// This term avoids "glowy" background objects OR both are *really* blurry in the far field
            saturate(max(r_B - r_A + 1.0, (0.01 - r_A) * invB)) *
           
            // Gaussian kernel of "radius" based on pixel B.
            exp(-square(dist * 1.4142 / r_B));
        coverage_sample += lerp(wNormal, 1.0, nearFieldness_A);


        float4 near;
#if SPEED_DIRECTION
        near.a = square(saturate(r_B * invNearBlurRadiusPixels));
        near.rgb = centerColor * near.a;
#else
        near = texelFetch(nearColorBuffer, clamp(other, int2(0), textureSize(nearColorBuffer, 0) - int2(1)), 0);
#endif
        float weightNear = exp(-square(dist * invNearBlurRadiusPixels));

        totalCoverageNear += weightNear;
        resultColorNear += near * weightNear;
    }
    */

    // Accumulate (with premultiplied coverage)
    resultColor   += color_sample * coverage_sample;
    totalCoverage += coverage_sample;
}
#       undef COMPUTE_RADIUS_SAMPLE
    }

    /*

#   if SPEED_DIRECTION
        // Retain the packed radius on the first pass.  On the second pass it is not needed.
        blurResult.a = packedA;
#   else
        // Vertical, second pass
        //blurResult.a = 1.0;
#   endif

    // Normalize the blur
    blurResult.rgb /= blurWeightSum;
    nearResult     /= max(nearWeightSum, 0.000001); 
    
#   if ! SPEED_DIRECTION

    // Boost the coverage of the near field by this factor.  Should always be >= 1
    //
    // Make this larger if near-field objects seem too transparent
    //
    // Make this smaller if an obvious line is visible between the near-field blur and the mid-field sharp region
    // when looking at a textured ground plane.

    {
        // Needs to increase with field of view
        float coverageBoost = fieldOfView;
        // Increase near field coverage. We can't just scale by coverageBoost
        // even though we're using premultiplied alpha because there
        // is nonlinear clamping of alpha at 1.0. 
        
        // If this minimum value is too large, then there will be an intensity
        // dip when compositing the premultiplied-alpha value, since it will not
        // be correctly premultiplied.
        const float minimumValue = 0.000001;
        
        float oldAlpha = nearResult.a;
        float newAlpha = clamp(smoothstep(oldAlpha, 0.0, 0.025 / coverageBoost), minimumValue, 1.0);

        nearResult.rgb = nearResult.rgb * (max(minimumValue, newAlpha) / max(oldAlpha, minimumValue));
        nearResult.a = newAlpha;
    }
#   endif




#if SPEED_DIRECTION
    resultColor /= totalCoverage;
    nearResult = resultColorNear/totalCoverageNear;
#else
    float3 result;
    {// HUGO EXPERIMENT -----------------------------------------------------------------------------------
        float3 blurry = blurResult/totalCoverage;
        float4 blurryNear = resultColorNear/totalCoverageNear;
        float normRadius = (CoC_ratio_center*radius_center/float(maxCoCRadiusPixels)); //* 0.5 + 0.5;
        result = max(lerp(centerColor, 
                      blurry,
                      saturate(-12.0 * normRadius)) * (1.0 - blurryNear.a),
                      //1 - saturate(-12.0 * normRadius)) * (1.0 - blurryNear.a),
                      //saturate(-12.0 * normRadius)) ,
                vec3(0)) + blurryNear.rgb;

        //resultColor = vec3(saturate(-12.0 * normRadius));
        //resultColor = resultColor/totalCoverage;
        blurResult = result;
    }
#endif
    */

    // We never divide by zero because we always sample the pixel itself.
    resultColor /= totalCoverage;
    // HUGO ------------------------------------------------------------------------
    //resultColor = result;
    //resultColor = vec3(CoC_center*0.5+0.5);
}
