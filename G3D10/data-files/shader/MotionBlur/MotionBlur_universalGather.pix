#version 330
/**
  \file data-files/shader/MotionBlur/MotionBlur_gather.pix

  This is designed to read from a G3D-style velocity (optical flow) buffer.
  For performance, you could just write out velocity in the desired 
  format rather than adjusting it per texture fetch.

  G3D Innovation Engine http://casual-effects.com/g3d
  Copyright 2000-2019, Morgan McGuire
  All rights reserved
  Available under the BSD License
*/
// Included by all of the blur shaders
#include <compatibility.glsl>

#expect maxBlurRadius "int > 0"
#expect MODEL "PHYSICAL, ARTIST, or NONE"
#expect numSamplesOdd
#expect SPEED_DIRECTION "1 if sampling in speed direction, 0 if sampling perpendicularly to speed direction"
#expect DEPTH_OF_FIELD
#expect MOTION_BLUR

// Set to 0 to make very thin objects appear correct, set to 1 to reduce noise but
// undersample single-pixel thick moving objects
#define SMOOTHER 1

/** Unprocessed differences between previous and current frame in screen space. Guard band. */
uniform sampler2D   SS_POSITION_CHANGE_buffer;
uniform vec4        SS_POSITION_CHANGE_readMultiplyFirst;
uniform vec4        SS_POSITION_CHANGE_readAddSecond;

/** Uses the same encoding as SS_POSITION_CHANGE but has three channels.  No guard band. */
uniform sampler2D   neighborMinMax_buffer;

/** Source image in RGB, normalized CoC in A. Used for DoF. */
uniform sampler2D	blurSourceBuffer;
uniform float       lowResolutionFactor;
uniform int         maxCoCRadiusPixels;
uniform float       invNearBlurRadiusPixels;

#if SPEED_DIRECTION
    const bool isSpeedDirection = true;
#else
    const bool isSpeedDirection = false;
#endif

/** No guard band. */
uniform sampler2D   colorBuffer;

/** Typical hyperbolic depth buffer: close values are greater than distant values. Guard band. */
uniform sampler2D   depthBuffer;

/** 32x32 tiled random numbers */
uniform sampler2D   randomBuffer;

/** In fraction of frame duration */
uniform float       exposureTime;

uniform ivec2       trimBandThickness;

/** Amount on [-0.5, 0.5] to randomly perturb samples by at each pixel */
float2              jitter;

/* Measured in pixels
   Make this smaller to better hide tile boundaries
   Make this bigger to get smoother blur (less noise) */
#define varianceThreshold 1.5

#if SPEED_DIRECTION
out float4 resultColor;
#else
out float3 resultColor;
#endif
/*
#if SPEED_DIRECTION // HUGO ---------------------------------------
#if __VERSION__ < 130   // HUGO ---------------------------------------
#	define nearResult gl_FragData[0]
#	define blurResult gl_FragData[1]
#else
layout(location = 0) out float4 nearResult;
layout(location = 1) out float4 blurResult;
#endif
#else
out float3 blurResult;
#endif // SPEED_DIRECTION
*/

// Constant indicating locations wme we clamp against the minimum PSF, 1/2 pixel
const float HALF_PIX = 0.5;

/** Computes a pseudo-random number on [0, 1] from pixel position c. */
float hash(int2 c) {
#   if numSamplesOdd <= 5
	    // Use a simple checkerboard if you have very few samples; this gives too much ghosting 
        // for many scenes, however
        return float(int(c.x + c.y) & 1) * 0.5 + 0.25;
#   else
        return texelFetch(randomBuffer, int2(c.x & 31, c.y & 31), 0).r;
#   endif
}

float square(float x) { return x * x; }


/** Called from readAdjustedVelocity() and readAdjustedNeighborhoodVelocity() 

    (xy) is the velocity, z is the minimum blur radius in the tile for neighbor velocity
    and zero for expressive motion.
*/
//float3 readAdjustedVelocity(int2 C, sampler2D sampler, out float r) {
float3 readAdjustedVelocity(int2 C, int2 A, sampler2D sampler, out float r, out float CoC_ratio) { // HUGO ---------------------------------
    
	
#if !MOTION_BLUR
    //q.xy = normalize(q.xy);
    float3 q = float3(1.0, 0.0, 0.0);
    r = 0.01;
#else
    // Raw screen-space movement
    float3 q = texelFetch(sampler, C, 0).xyz * SS_POSITION_CHANGE_readMultiplyFirst.xyz + SS_POSITION_CHANGE_readAddSecond.xyz;
    float lenq = length(q.xy);


    // Convert the velocity to be a radius instead of a diameter, and scale it by
	// the exposure time
    r = lenq * 0.5 * exposureTime;
    q.z *= 0.5 * exposureTime;
    //bool rMuchLargerThanZero = (r >= 0.01);
    bool rMuchLargerThanZero = (r >= 0.1);  // HUGO -------------------------

    // Clamp to the usable distance
    r = clamp(r, HALF_PIX, float(maxBlurRadius));
	
    // If r is nearly zero, then we risk having a negligible value in lenq, so just return the original
    // vector, which can't be that long anyway if we entered this case
    if (rMuchLargerThanZero) {
        // Adjust q's length based on the newly clamped radius
        q.xy *= (r / lenq);
    }
    else
    {
        q.xy = float2(1.0, 0.0);
    }
#endif // !MOTION_BLUR

#if !SPEED_DIRECTION
    //if (!speedDirection){
        q.xy = float2(-q.y, q.x);
        //r=HALF_PIX;
        r=0.01;
    //}
#endif

#if DEPTH_OF_FIELD

    //float DoF_r = abs( (texelFetch(blurSourceBuffer, A, 0).a * 2.0) - 1.0 );
    //r += float(maxCoCRadiusPixels) * DoF_r;
    //r += lerp(0.0,float(maxCoCRadiusPixels), DoF_r);

    float DoF_r = (texelFetch(blurSourceBuffer, A, 0).a * 2.0) - 1.0;
    //float near = square(saturate(DoF_r * invNearBlurRadiusPixels));
    r += float(maxCoCRadiusPixels) * abs(DoF_r);
    CoC_ratio = DoF_r/r;
    //r *= sign(DoF_r);
#else
    CoC_ratio = 0.0;
#endif

    return q;
}

/** 
  V[C] in the paper.

  v = half-velocity vector 
  r = magnitude of v
*/
/*
float3 readAdjustedVelocity(int2 C, out float r) {
    return readAdjustedVelocity(C, SS_POSITION_CHANGE_buffer, r);
}
*/
float3 readAdjustedVelocity(int2 C, int2 A, out float r, out float CoC_ratio) {  // HUGO ---------------------------------
    return readAdjustedVelocity(C, A, SS_POSITION_CHANGE_buffer, r, CoC_ratio);
}



/** NeighborMax[C] from the paper */
/*
float3 readAdjustedNeighborhoodVelocity(int2 C, out float r) {
    return readAdjustedVelocity(int2(C / float(maxBlurRadius)), neighborMinMax_buffer, r);
}
*/
float3 readAdjustedNeighborhoodVelocity(int2 C, int2 A, out float r, out float CoC_ratio) {  // HUGO ---------------------------------
    return readAdjustedVelocity(int2(C / float(maxBlurRadius)), A, neighborMinMax_buffer, r, CoC_ratio);
}

float cone(float dist, float r) {
    return saturate(1.0 - abs(dist) / r);
}


float fastCone(float dist, float invR) {
    return saturate(1.0 - abs(dist) * invR);
}

// A cone filter with maximum weight 1 at dist = 0 and min weight 0 at |v|=dist.
float cylinder(float dist, float r) {
    //return 1.0 - smoothstep(r * 0.95, r * 1.05, abs(dist));

    // Alternative: (marginally faster on GeForce, comparable quality)
    return sign(r - abs(dist)) * 0.5 + 0.5;

    // The following gives nearly identical results and may be faster on some hardware,
    // but is slower on GeForce
    //    return (abs(dist) <= r) ? 1.0 : 0.0;
}


/** 0 if depth_A << depth_B, 1 if depth_A >> z_depth, fades between when they are close */
float softDepthCompare(float depth_A, float depth_B) {
    // World space distance over which we are conservative about the classification
    // of "foreground" vs. "background".  Must be > 0.  
    // Increase if slanted surfaces aren't blurring enough.
    // Decrease if the background is bleeding into the foreground.
    // Fairly insensitive
    const float SOFT_DEPTH_EXTENT = 0.01;

    return saturate(1.0 - (depth_B - depth_A) / SOFT_DEPTH_EXTENT);
}


// For linear Z values where more negative = farther away from camera
float softZCompare(float z_A, float z_B) {
    // World space distance over which we are conservative about the classification
    // of "foreground" vs. "background".  Must be > 0.  
    // Increase if slanted surfaces aren't blurring enough.
    // Decrease if the background is bleeding into the foreground.
    // Fairly insensitive
    const float SOFT_Z_EXTENT = 0.1;

    return saturate(1.0 - (z_A - z_B) / SOFT_Z_EXTENT);
}

bool inNearField(float radiusPixels) {
    return radiusPixels > 0.25;
}


void main() {

    
    // Size of the screen
    int2 SCREEN_MAX = textureSize(colorBuffer, 0).xy + trimBandThickness * 2 - int2(1);
    int2 NO_TRIM_BAND_SCREEN_MAX = textureSize(colorBuffer, 0).xy - int2(1);

    // Center pixel
    int2 me       = int2(gl_FragCoord.xy);

#if !DEPTH_OF_FIELD && !MOTION_BLUR
    resultColor.rgb = texelFetch(colorBuffer, me - trimBandThickness, 0).rgb;
    return;
#endif

    // Location of center pixel in the downsized 
    // Account for the scaling down to 50% of original dimensions during blur
	//int2 A = int2(gl_FragCoord.xy * (direction * lowResolutionFactor + (ivec2(1) - direction)));
    int2 A = int2(gl_FragCoord.xy * lowResolutionFactor);
    float CoC_center = (texelFetch(blurSourceBuffer, A, 0).a * 2.0) - 1.0;
    float DoF_r = abs(CoC_center);
    DoF_r = float(maxCoCRadiusPixels) * DoF_r;


    float4 centerColor = texelFetch(colorBuffer, me - trimBandThickness, 0);
    resultColor.rgb = vec3(0);
#if SPEED_DIRECTION
    resultColor.a = -1.0;
#endif

    float totalCoverage = 0;
    float totalCoverageNear = 0;
    float4 resultColorNear;

    float depth_center = texelFetch(depthBuffer, me, 0).x;
    
    // Compute the maximum PSF in the neighborhood
    float r_neighborhood;
    float r_neighborhood_CoC_ratio;
    float2 v_neighborhood;
    float rmin_neighborhood;
    { 
       //float3 temp = readAdjustedNeighborhoodVelocity(me - trimBandThickness, r_neighborhood);
       float3 temp = readAdjustedNeighborhoodVelocity(me - trimBandThickness, A, r_neighborhood, r_neighborhood_CoC_ratio);   // HUGO ----------------------
       v_neighborhood    = temp.xy;
       rmin_neighborhood = temp.z;
    }
    

    // Compute PSF at me (this pixel)
    float  radius_center;
    float CoC_ratio_center;
    //float2 velocity_center = readAdjustedVelocity(me, radius_center).xy;
    float2 velocity_center = readAdjustedVelocity(me, A, radius_center, CoC_ratio_center).xy; // HUGO ---------------------------------
    
    // A pseudo-random number on [-0.5, 0.5]
    float jitter = hash(me) - 0.5;
    jitter *= saturate( (1.0-abs(CoC_ratio_center)) * radius_center*0.03); // HUGO ----------------------------
    //jitter = 0.0; // HUGO ----------------------------

    /////////////////////////////////////////////////////////////////////////// DEBUG
    //resultColor.rgb = vec3(radius_center/50.0);
    //return;

    /*
    {
    #if !MOTION_BLUR
        float ratioDoF = abs(CoC_ratio_center);
        radius_center *= ratioDoF;
    #endif
    }
    */

    // Above this pixel displacement, the center velocity overrides the neighborhood.
    // This ensures the overblurring occurs only on the interior of fast-moving objects
    // instead of in tiles outside of moving objects.
    const float centerOverrideThresholdPixels = 5;

    // Let w be a velocity direction (i.e., w is "omega", a unit vector in screen-space)
    // Let r be a half-velocity magnitude (i.e., a point-spread function radius)
    // If the center is moving very fast, sample along the center direction to avoid tile polution
    //float2 w_neighborhood = normalize((radius_center >= centerOverrideThresholdPixels) ? velocity_center : v_neighborhood);
    float2 w_neighborhood = normalize((radius_center >= centerOverrideThresholdPixels + DoF_r) ? velocity_center : v_neighborhood); // HUGO ----------------------

    // Choose the direction at this pixel to be the same as w_neighborhood if this pixel is not itself moving.
    // Don't adjust the radious--doing so causes the background to blur out when it is static.
    //float2 w_center = (radius_center < varianceThreshold) ? w_neighborhood : normalize(velocity_center);
    float2 w_center = (radius_center < varianceThreshold + DoF_r) ? w_neighborhood : normalize(velocity_center); // HUGO ----------------------

    
    

    // Accumulated color; start with the center sample
    // Higher initial weight increases the ability of the background
    // to overcome the out-blurred part of moving objects
    float invRadius_center = 1.0 / radius_center; 
    // float totalCoverage = (float(numSamplesOdd) / 40.0) * invRadius_center;
    // resultColor *= totalCoverage;
    float initialCoverage = (float(numSamplesOdd) / 40.0) * invRadius_center; // HUGO -------------------------------
    //float initialCoverage = 0.001;
    totalCoverage += initialCoverage;  // HUGO --------------------
    resultColor.rgb += centerColor.rgb*initialCoverage;

    float radius_sample = r_neighborhood;
    float radius_CoC_ratio = r_neighborhood_CoC_ratio;

    // HUGO (DEBUG ONLY) -------------------------------------------------------------------------------------------------
    //resultColor.xy = abs(v_neighborhood);
    //resultColor.z = 0.0;
    //resultColor = vec3(radius_center/maxCoCRadiusPixels);
    //vec3(texelFetch(blurSourceBuffer, A, 0).a);
    

    // The following branch is coherent on tile boundaries. It gives about a 12% speedup
    // to motion blur due to camera motion. Ideally, the tile boundaries are also warp (8 pixel) boundaries
    // to avoid divergence.
    //if ((rmin_neighborhood >= r_neighborhood) || 
    //    ((rmin_neighborhood >= r_neighborhood * 0.65) && (rmin_neighborhood >= 4))) {
    if (false) { // HUGO -----------------------------------------------------------------------------------------

        // Everything in this neighborhood is moving pretty fast; assume that
        // radius_sample == r_neighborhood and don't bother spending
        // bandwidth to actually read it per pixel
#       define COMPUTE_RADIUS_SAMPLE() 
// The inner loop of MotionBlur_gather.pix
// Sample along the largest PSF vector in the neighborhood
for (int i = 0; i < numSamplesOdd; ++i) {

    // The original algorithm ignores the center sample, but we include it because doing so
    // produces better results for thin objects at the expense of adding a slight amount of grain.
    // That is because the jitter will bounce this slightly off the actual center
#   if SMOOTHER
        if (i == numSamplesOdd / 2) { continue; }
#   endif
        
    // Signed step distance from X to Y.
    // Because cone(r_Y) = 0, we need this to never reach +/- r_neighborhood, even with jitter.
    // If this value is even slightly off then gaps and bands will appear in the blur.
    // This pattern is slightly different than the original paper.
    float t = clamp(2.4 * (float(i) + 1.0 + jitter) / (numSamplesOdd + 1.0) - 1.2, -1, 1);
    float dist = t * r_neighborhood;

    float2 sampling_direction = (((i & 1) == 1) ? w_center : w_neighborhood);

    float2 offset =
        // Alternate between the neighborhood direction and this pixel's direction.
        // This significantly helps avoid tile boundary problems when other are
        // two large velocities in a tile. Favor the neighborhood velocity on the farthest 
        // out taps (which also means that we get slightly more neighborhood taps, as we'd like)
        dist * sampling_direction;
        
    // Point being considered; offset and round to the nearest pixel center.
    // Then, clamp to the screen bounds
    int2 other = clamp(int2(offset + gl_FragCoord.xy), trimBandThickness, SCREEN_MAX);

    float depth_sample = texelFetch(depthBuffer, other, 0).x;

    // is other in the foreground or background of me?
    float inFront = softDepthCompare(depth_center, depth_sample);
    float inBack  = softDepthCompare(depth_sample, depth_center);
    

    // HUGO -------------------------------------------
    //inFront = 0.0;
    //inBack = 0.0;
    //float tempFront = inFront;
    //inFront = saturate(CoC_ratio_center) * inFront + (1-saturate(CoC_ratio_center)) * inBack;
    //inBack = saturate(CoC_ratio_center) * inBack + (1-saturate(CoC_ratio_center)) * tempFront;

    // Relative contribution of sample to the center
    float coverage_sample = 0.0;

    // Blurry me, estimate background
    coverage_sample += inBack * fastCone(dist, invRadius_center);
    //coverage_sample += inBack * 0.0; // HUGO --------------------------;
    //coverage_sample += max(inBack, radius_CoC_ratio) * 10.0; // HUGO --------------------------
    //coverage_sample += inBack * fastCone(dist, invRadius_center)  * (1+20*saturate(CoC_ratio_center)); // HUGO --------------------------;

    COMPUTE_RADIUS_SAMPLE();

    float3 color_sample    = texelFetch(colorBuffer, clamp(other - trimBandThickness, ivec2(0), NO_TRIM_BAND_SCREEN_MAX), 0).rgb;

    // Blurry other over any me
    coverage_sample += inFront * cone(dist, radius_sample);
    //coverage_sample += inFront * 0.0; // HUGO --------------------------
    //coverage_sample += max(inFront, radius_CoC_ratio) * 10.0; // HUGO --------------------------
    //coverage_sample += inFront * cone(dist, radius_sample) * (1+20*saturate(CoC_ratio_center)); // HUGO --------------------------

    // Mutually blurry me and other
    coverage_sample += 
    //0; // HUGO --------------------------------------------------------------------------------------------
		// Optimized implementation
		cylinder(dist, min(radius_center, radius_sample)) * 2.0;
		

//        coverage_sample = saturate(coverage_sample * abs(dot(normalize(velocity_sample), sampling_direction)));
//       coverage_sample = saturate(dot(normalize(velocity_sample), sampling_direction));
		// Code from paper:
		// cylinder(dist, radius_center) * cylinder(dist, radius_sample) * 2.0;


    //coverage_sample = 0.0; // HUGO -------------------------------------------------------------------

    // Accumulate (with premultiplied coverage)
    //resultColor   += color_sample * coverage_sample;
    resultColor.rgb   += color_sample * coverage_sample;
    

    totalCoverage += coverage_sample;
}
    } else {
        // Read true velocity at each pixel
#       undef COMPUTE_RADIUS_SAMPLE

        // The actual velocity_sample vector will be ignored by the code below,
        // but the magnitude (radius_sample) of the blur is used.
//#       define COMPUTE_RADIUS_SAMPLE() { float2 velocity_sample = readAdjustedVelocity(other, radius_sample).xy; }
#       define COMPUTE_RADIUS_SAMPLE() { float2 velocity_sample = readAdjustedVelocity(other, B, radius_sample, radius_CoC_ratio).xy; }  // HUGO -----------
// The inner loop of MotionBlur_gather.pix
// Sample along the largest PSF vector in the neighborhood
for (int i = 0; i < numSamplesOdd; ++i) {

    // The original algorithm ignores the center sample, but we include it because doing so
    // produces better results for thin objects at the expense of adding a slight amount of grain.
    // That is because the jitter will bounce this slightly off the actual center
#   if SMOOTHER
        if (i == numSamplesOdd / 2) { continue; }
#   endif
        
    // Signed step distance from X to Y.
    // Because cone(r_Y) = 0, we need this to never reach +/- r_neighborhood, even with jitter.
    // If this value is even slightly off then gaps and bands will appear in the blur.
    // This pattern is slightly different than the original paper.
    float t = clamp(2.4 * (float(i) + 1.0 + jitter) / (numSamplesOdd + 1.0) - 1.2, -1, 1);
    //float t = clamp(2.4 * (float(i) + 1.0) / (numSamplesOdd + 1.0) - 1.2, -1, 1); // HUGO -------------------------------------
    // float dist = t * r_neighborhood;
    float dist = t * (maxCoCRadiusPixels);//28; ///20; // HUGO ----------------------------------------------------------------------------

    float2 sampling_direction = (((i & 1) == 1) ? w_center : w_neighborhood);

    float2 offset =
        // Alternate between the neighborhood direction and this pixel's direction.
        // This significantly helps avoid tile boundary problems when other are
        // two large velocities in a tile. Favor the neighborhood velocity on the farthest 
        // out taps (which also means that we get slightly more neighborhood taps, as we'd like)
        dist * sampling_direction;
        
    // Point being considered; offset and round to the nearest pixel center.
    // Then, clamp to the screen bounds
    int2 other = clamp(int2(offset + gl_FragCoord.xy), trimBandThickness, SCREEN_MAX);
    int2 B = int2((offset + gl_FragCoord.xy) * lowResolutionFactor);

    COMPUTE_RADIUS_SAMPLE();
    //float2 velocity_sample = readAdjustedVelocity(other, B, radius_sample, radius_CoC_ratio).xy;

    float depth_sample = texelFetch(depthBuffer, other, 0).x;

    // is other in the foreground or background of me?
    float inFront = softDepthCompare(depth_center, depth_sample);
    float inBack  = softDepthCompare(depth_sample, depth_center);

    float4 color_sample    = texelFetch(colorBuffer, clamp(other - trimBandThickness, ivec2(0), NO_TRIM_BAND_SCREEN_MAX), 0);


    // Relative contribution of sample to the center
    float coverage_sample = 0.0;

    float ratioDoF = abs(radius_CoC_ratio);
    float ratioMB = 1.0-ratioDoF;
    float CoC_sample = texelFetch(blurSourceBuffer, B, 0).a * 2.0 - 1.0;
    //float CoC_sample = radius_sample*radius_CoC_ratio/maxCoCRadiusPixels;
    const float nearFieldBorder = 0.25;
    const float superNearFieldBorder = 0.50;
    //const float nearFieldTransition = 0.35;
    //const float farFieldTransition = 0.0;

/*
#if !MOTION_BLUR
    //radius_sample *= ratioDoF;
    radius_sample = abs(CoC_sample*maxCoCRadiusPixels);
#endif
*/
    
#if DEPTH_OF_FIELD
    

    //coverage_sample += float(CoC_sample <= nearFieldBorder && CoC_center <= nearFieldBorder); // Works to color background // HUGO ---------------------------------------------------------
    //coverage_sample += float(CoC_sample >  nearFieldBorder && CoC_center <= nearFieldBorder); // Works to color background // HUGO ---------------------------------------------------------
    //coverage_sample += float(CoC_sample >  nearFieldBorder && CoC_center >  nearFieldBorder); // Works to color background // HUGO ---------------------------------------------------------

    coverage_sample += float(CoC_sample <= superNearFieldBorder && CoC_center <= nearFieldBorder); // Works to color background // HUGO ---------------------------------------------------------
    coverage_sample += float(CoC_sample >  nearFieldBorder && CoC_center <= nearFieldBorder); // Works to color background // HUGO ---------------------------------------------------------
    coverage_sample += float(CoC_sample >  nearFieldBorder && CoC_center >  nearFieldBorder); // Works to color background // HUGO ---------------------------------------------------------
#endif


    /*
    float far_far = float(CoC_sample <= farFieldTransition && CoC_center <= farFieldTransition);
    float near_far = float(CoC_sample >  nearFieldTransition && CoC_center <= farFieldTransition);
    float near_near = float(CoC_sample >  nearFieldTransition && CoC_center >  nearFieldTransition);

    coverage_sample +=  lerp(far_far, near_far, (nearFieldTransition-CoC_sample)/(nearFieldTransition-nearFieldBorder));// Works to color background // HUGO ---------------------------------------------------------
    coverage_sample +=  lerp(near_far, near_near, (CoC_center-nearFieldTransition)/(nearFieldBorder-farFieldTransition));// Works to color background // HUGO ---------------------------------------------------------
    */

#if SPEED_DIRECTION // HUGO ---------------------------------------------------------------------------------------
    //float reach = abs(CoC_sample*maxCoCRadiusPixels);
    
    //float reach = abs(radius_sample);
    float reach = ratioMB * radius_sample/2 + abs(CoC_sample)*maxCoCRadiusPixels;   // Add only half of the speed as increased reach
    float isInReach = float(abs(dist) < reach);
    //resultColor.a = max(resultColor.a, saturate(CoC_sample*float(abs(dist) < reach)) );
    //resultColor.a = max(resultColor.a, saturate(CoC_sample*isInReach));
    float cornerRad = (reach - abs(dist))/reach;
    resultColor.a = max(resultColor.a, saturate(cornerRad*isInReach));

    //coverage_sample *= float(abs(dist) < reach);
    coverage_sample *= float(abs(dist) < reach) * exp(-square(dist * invNearBlurRadiusPixels));


#else
/*
    float reach = abs(color_sample.a*maxCoCRadiusPixels);
    coverage_sample *= float(abs(dist) < reach);
*/
    float reach = max(abs(color_sample.a*maxCoCRadiusPixels) , abs(CoC_sample*maxCoCRadiusPixels));
    //coverage_sample *= float(abs(dist) < reach) * exp(-square(dist * invNearBlurRadiusPixels));
    coverage_sample *= float(abs(dist)*1.4 < reach) * exp(-square(dist * invNearBlurRadiusPixels));
#endif


#if MOTION_BLUR && SPEED_DIRECTION
    float mbCoverage = 0;
    //coverage_sample += radius_sample*ratioMB/maxCoCRadiusPixels;

    // Blurry me, estimate background
    mbCoverage += inBack * fastCone(dist, invRadius_center);

    // Blurry other over any me
    mbCoverage += inFront * cone(dist, radius_sample);

    // Mutually blurry me and other
    mbCoverage += 
        //0.0; // HUGO -------------------------------------------------------------------------------------- 
		// Optimized implementation
		cylinder(dist, min(radius_center, radius_sample)) * 2.0;
		
        // UNUSED BY DEFAULT
//        coverage_sample = saturate(coverage_sample * abs(dot(normalize(velocity_sample), sampling_direction)));
//       coverage_sample = saturate(dot(normalize(velocity_sample), sampling_direction));
		// Code from paper:
		// cylinder(dist, radius_center) * cylinder(dist, radius_sample) * 2.0;

    reach = abs(radius_sample);
    //coverage_sample += mbCoverage * float(abs(dist) < reach) ;
    coverage_sample += 0.33 * mbCoverage * float(abs(dist) < reach) ;
#endif
    
    /////////////////////////////////////////////////////////////////////////// DEBUG
    //resultColor.rgb = vec3(radius_sample/50.0);
    //return;
    

    //float3 color_sample    = texelFetch(colorBuffer, clamp(other - trimBandThickness, ivec2(0), NO_TRIM_BAND_SCREEN_MAX), 0).rgb;

    
    coverage_sample += 0.0; // HUGO --------------------------------------------------------------------------------------
    //coverage_sample += max(inFront, radius_CoC_ratio) *  cone(dist, radius_sample); // HUGO ----------------------------------------------
    //coverage_sample += cone(dist, radius_sample); // HUGO ----------------------------------------------
    //coverage_sample += radius_CoC_ratio; //max(inFront, radius_CoC_ratio);


    
    
    //coverage_sample = float(max(radius_sample, radius_center) > abs(dist)); // HUGO ---------------------------------------------------------------------------------------
    //coverage_sample = cylinder(dist, max(radius_center, radius_sample))/(abs(dist)+0.01); // HUGO ---------------------------------------------------------------------------------------



    // Accumulate (with premultiplied coverage)
    resultColor.rgb   += color_sample.rgb * coverage_sample;
    totalCoverage += coverage_sample;
}
#       undef COMPUTE_RADIUS_SAMPLE
    }

    

    // We never divide by zero because we always sample the pixel itself.
    //resultColor /= totalCoverage;
    // HUGO ------------------------------------------------------------------------
    //resultColor = result;
    //resultColor = vec3(CoC_center*0.5+0.5);
    

#if SPEED_DIRECTION
    resultColor.rgb /= totalCoverage;
#else
    resultColor.rgb /= totalCoverage;
    //resultColor = vec3(centerColor.a*0.5+0.5);
#endif
}
